{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f29486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ddpg\n",
    "import sys\n",
    "sys.path.append('C:/Users/owner/.mujoco/mujoco200/bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0effe36d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 300)               5400      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 400)               120400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 2406      \n",
      "=================================================================\n",
      "Total params: 128,206\n",
      "Trainable params: 128,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 300)               5400      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 400)               120400    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 2406      \n",
      "=================================================================\n",
      "Total params: 128,206\n",
      "Trainable params: 128,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 17)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 300)          5400        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 400)          120400      dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 300)          2100        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 700)          0           dense_7[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 300)          210300      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            301         dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 338,501\n",
      "Trainable params: 338,501\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 17)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 300)          5400        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 400)          120400      dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 300)          2100        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 700)          0           dense_12[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 300)          210300      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            301         dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 338,501\n",
      "Trainable params: 338,501\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 17)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 17)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 34)           0           input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Hidden0 (Dense)                 (None, 400)          14000       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "L1 (Dense)                      (None, 200)          80200       Hidden0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "L2 (Dense)                      (None, 200)          40200       L1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "L3 (Dense)                      (None, 100)          20100       L2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "mean (Dense)                    (None, 12)           1212        L3[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 155,712\n",
      "Trainable params: 155,712\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "    env_name = \"HalfCheetah-v2\" #\"InvertedPendulum-v2\" \"HalfCheetah-v2\"\n",
    "\n",
    "    EPOCHS =  100\n",
    "    MAX_EPISODE_LENGTH = 200\n",
    "    #RENDER_EVERY = 10\n",
    "    START_STEPS = 2000\n",
    "\n",
    "    total_steps = MAX_EPISODE_LENGTH * EPOCHS\n",
    "\n",
    "    env = gym.make(env_name)\n",
    "    state_dim = env.observation_space.shape[0]\n",
    "    action_dim = env.action_space.shape[0]\n",
    "    action_lim = env.action_space.high[0]\n",
    "\n",
    "    agent = ddpg.DDPG(state_dim, action_dim)\n",
    "\n",
    "    state, reward, done, ep_rew, ep_len, ep_cnt = env.reset(), 0, False, [0.0], 0, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5640d7b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLFW error (code %d): %s 65544 b'Vulkan: Failed to query instance extension count: Initialization of an object could not be completed for implementation-specific reasons'\n",
      "Creating window glfw\n",
      "Episode: 1, Reward: -99.93753468418224\n",
      "upgrade complete 1 times\n",
      "Episode: 2, Reward: 8.966833918721177\n",
      "upgrade complete 2 times\n",
      "Episode: 3, Reward: -74.08472619649896\n",
      "upgrade complete 3 times\n",
      "Episode: 4, Reward: -1.3862751136256817\n",
      "upgrade complete 4 times\n",
      "Episode: 5, Reward: -83.07532723541667\n",
      "upgrade complete 5 times\n",
      "Episode: 6, Reward: -65.57491137647787\n",
      "max_act_var\n",
      "[[-3.2588382  -2.018472   -2.0660899  -0.56134254 -2.854063   -2.068356  ]\n",
      " [-2.5584621  -2.077818   -1.8818812  -0.38209042 -1.8530377  -2.336681  ]\n",
      " [-3.3423367  -3.4402928  -2.179785   -0.64718366 -3.241771   -3.8542204 ]\n",
      " [-3.2749698  -2.964269   -2.6037173  -0.98179555 -2.969855   -3.1177442 ]\n",
      " [-2.4717867  -1.9504901  -1.940612   -1.0438054  -1.96306    -2.7010372 ]]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8384159   0.04712727  0.5643347   0.70129955 -0.46677226  0.7292584 ]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8384159   0.04712727  0.5643347   0.70129955 -0.46677226  0.7292584 ]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8384159   0.04712727  0.5643347   0.70129955 -0.46677226  0.7292584 ]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8384159   0.04712727  0.5643347   0.70129955 -0.46677226  0.7292584 ]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8384159   0.04712727  0.5643347   0.70129955 -0.46677226  0.7292584 ]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8384159   0.04712727  0.5643347   0.70129955 -0.46677226  0.7292584 ]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8384159   0.04712727  0.5643347   0.70129955 -0.46677226  0.7292584 ]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8384159   0.04712727  0.5643347   0.70129955 -0.46677226  0.7292584 ]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8384159   0.04712727  0.5643347   0.70129955 -0.46677226  0.7292584 ]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8384159   0.04712727  0.5643347   0.70129955 -0.46677226  0.7292584 ]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.85170996 -0.80989665 -0.07526983  0.32380214  0.6764304  -0.51607007]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.85170996 -0.80989665 -0.07526983  0.32380214  0.6764304  -0.51607007]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.85170996 -0.80989665 -0.07526983  0.32380214  0.6764304  -0.51607007]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.85170996 -0.80989665 -0.07526983  0.32380214  0.6764304  -0.51607007]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.85170996 -0.80989665 -0.07526983  0.32380214  0.6764304  -0.51607007]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.85170996 -0.80989665 -0.07526983  0.32380214  0.6764304  -0.51607007]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.85170996 -0.80989665 -0.07526983  0.32380214  0.6764304  -0.51607007]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.85170996 -0.80989665 -0.07526983  0.32380214  0.6764304  -0.51607007]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.85170996 -0.80989665 -0.07526983  0.32380214  0.6764304  -0.51607007]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.85170996 -0.80989665 -0.07526983  0.32380214  0.6764304  -0.51607007]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8765217   0.32108906  0.5826982   0.9291331  -0.96143734 -0.66516745]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8765217   0.32108906  0.5826982   0.9291331  -0.96143734 -0.66516745]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8765217   0.32108906  0.5826982   0.9291331  -0.96143734 -0.66516745]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8765217   0.32108906  0.5826982   0.9291331  -0.96143734 -0.66516745]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8765217   0.32108906  0.5826982   0.9291331  -0.96143734 -0.66516745]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8765217   0.32108906  0.5826982   0.9291331  -0.96143734 -0.66516745]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8765217   0.32108906  0.5826982   0.9291331  -0.96143734 -0.66516745]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8765217   0.32108906  0.5826982   0.9291331  -0.96143734 -0.66516745]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8765217   0.32108906  0.5826982   0.9291331  -0.96143734 -0.66516745]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.8765217   0.32108906  0.5826982   0.9291331  -0.96143734 -0.66516745]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9428166  -0.3992025   0.06780045  0.602431   -1.0191147  -0.18436189]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9428166  -0.3992025   0.06780045  0.602431   -1.0191147  -0.18436189]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9428166  -0.3992025   0.06780045  0.602431   -1.0191147  -0.18436189]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9428166  -0.3992025   0.06780045  0.602431   -1.0191147  -0.18436189]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9428166  -0.3992025   0.06780045  0.602431   -1.0191147  -0.18436189]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9428166  -0.3992025   0.06780045  0.602431   -1.0191147  -0.18436189]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9428166  -0.3992025   0.06780045  0.602431   -1.0191147  -0.18436189]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9428166  -0.3992025   0.06780045  0.602431   -1.0191147  -0.18436189]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9428166  -0.3992025   0.06780045  0.602431   -1.0191147  -0.18436189]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9428166  -0.3992025   0.06780045  0.602431   -1.0191147  -0.18436189]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9662787  -1.0354557  -0.02238283  0.60767525  1.0681807  -0.8257585 ]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9662787  -1.0354557  -0.02238283  0.60767525  1.0681807  -0.8257585 ]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9662787  -1.0354557  -0.02238283  0.60767525  1.0681807  -0.8257585 ]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9662787  -1.0354557  -0.02238283  0.60767525  1.0681807  -0.8257585 ]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9662787  -1.0354557  -0.02238283  0.60767525  1.0681807  -0.8257585 ]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9662787  -1.0354557  -0.02238283  0.60767525  1.0681807  -0.8257585 ]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9662787  -1.0354557  -0.02238283  0.60767525  1.0681807  -0.8257585 ]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9662787  -1.0354557  -0.02238283  0.60767525  1.0681807  -0.8257585 ]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9662787  -1.0354557  -0.02238283  0.60767525  1.0681807  -0.8257585 ]\n",
      "나 여깄담\n",
      "<class 'numpy.ndarray'>\n",
      "[ 0.9662787  -1.0354557  -0.02238283  0.60767525  1.0681807  -0.8257585 ]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-9240f98ca135>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m                 \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m4\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m                     \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarg_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"upgrade complete {} times\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mep_cnt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\jupyter\\ddpg_ver2_half\\ddpg.py\u001b[0m in \u001b[0;36mtarg_update\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtarg_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_Q_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_policy_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\jupyter\\ddpg_ver2_half\\critic.py\u001b[0m in \u001b[0;36mtarget_Q_update\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtarget_Q_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m         \u001b[0mtarg_pi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarg_Q\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarg_Q\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTAU\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mpi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTAU\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtarg_pi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\anaconda3\\envs\\mujoco\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mget_weights\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2056\u001b[0m     \"\"\"\n\u001b[0;32m   2057\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2058\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2059\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2060\u001b[0m   def save(self,\n",
      "\u001b[1;32mc:\\users\\owner\\anaconda3\\envs\\mujoco\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mget_weights\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1829\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1830\u001b[0m         \u001b[0moutput_weights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1831\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1832\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1833\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mdoc_controls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_not_generate_docs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\anaconda3\\envs\\mujoco\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\anaconda3\\envs\\mujoco\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mbatch_get_value\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m   3742\u001b[0m   \"\"\"\n\u001b[0;32m   3743\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3744\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3745\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3746\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\anaconda3\\envs\\mujoco\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   3742\u001b[0m   \"\"\"\n\u001b[0;32m   3743\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3744\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3745\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3746\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot get value inside Tensorflow graph function.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\anaconda3\\envs\\mujoco\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    626\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 628\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    629\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    630\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32mc:\\users\\owner\\anaconda3\\envs\\mujoco\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    701\u001b[0m     \"\"\"\n\u001b[0;32m    702\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 703\u001b[1;33m       \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    704\u001b[0m     \u001b[1;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    705\u001b[0m     \u001b[1;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\anaconda3\\envs\\mujoco\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    680\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    681\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 682\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    683\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\anaconda3\\envs\\mujoco\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[1;34m()\u001b[0m\n\u001b[0;32m    671\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[1;32m--> 673\u001b[1;33m           self._handle, self._dtype)\n\u001b[0m\u001b[0;32m    674\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\anaconda3\\envs\\mujoco\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m--> 470\u001b[1;33m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[0m\u001b[0;32m    471\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    472\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for t in range(total_steps):\n",
    "\n",
    "    env.render()\n",
    "\n",
    "    if t > START_STEPS:\n",
    "        action = agent.actor.get_action(state.reshape([1, state_dim]))\n",
    "        noise = 0.2 * np.random.randn(action_dim)\n",
    "        action = action_lim * action[0] + noise\n",
    "    else:\n",
    "        action = env.action_space.sample()\n",
    "\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "    ep_rew[-1] += reward\n",
    "    ep_len += 1\n",
    "\n",
    "    done = False\n",
    "\n",
    "    if ep_len == MAX_EPISODE_LENGTH:\n",
    "        done = True\n",
    "\n",
    "    agent.buffer.store(state, action, reward, next_state, done)\n",
    "\n",
    "    state = next_state       \n",
    "\n",
    "    if done:\n",
    "        ep_cnt += 1\n",
    "        print(f\"Episode: {ep_cnt}, Reward: {ep_rew[-1]}\")\n",
    "\n",
    "        ep_rew.append(0.0)\n",
    "\n",
    "        if t > 1000:\n",
    "            for i in range(100):\n",
    "                agent.replay_train()\n",
    "            agent.replay_predict()\n",
    "            for i in range(200):\n",
    "                agent.train(False)\n",
    "                if (i % 5) == 4 :\n",
    "                    agent.targ_update()\n",
    "\n",
    "        print(\"upgrade complete {} times\".format(ep_cnt))\n",
    "\n",
    "        state, reward, done, ep_len = env.reset(), 0, False, 0\n",
    "\n",
    "agent.actor.policy.save('./hg/RL/policy_v1.h5')\n",
    "agent.critic.Q.save('./hg/RL/critic_v1.h5')\n",
    "\n",
    "SMA_rewards = np.convolve(ep_rew, np.ones((5,))/5, mode='valid')\n",
    "#Plot learning curve\n",
    "plt.style.use('seaborn')\n",
    "plt.plot(SMA_rewards)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7079556",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 300)               5400      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 400)               120400    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 6)                 2406      \n",
      "=================================================================\n",
      "Total params: 128,206\n",
      "Trainable params: 128,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 300)               5400      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 400)               120400    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 2406      \n",
      "=================================================================\n",
      "Total params: 128,206\n",
      "Trainable params: 128,206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 17)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 300)          5400        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 400)          120400      dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 300)          2100        input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 700)          0           dense_7[0][0]                    \n",
      "                                                                 dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 300)          210300      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 1)            301         dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 338,501\n",
      "Trainable params: 338,501\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            [(None, 17)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 300)          5400        input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_6 (InputLayer)            [(None, 6)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 400)          120400      dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 300)          2100        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 700)          0           dense_12[0][0]                   \n",
      "                                                                 dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 300)          210300      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_15 (Dense)                (None, 1)            301         dense_14[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 338,501\n",
      "Trainable params: 338,501\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            [(None, 17)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            [(None, 17)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 34)           0           input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Hidden0 (Dense)                 (None, 400)          14000       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "L1 (Dense)                      (None, 200)          80200       Hidden0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "L2 (Dense)                      (None, 200)          40200       L1[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "L3 (Dense)                      (None, 100)          20100       L2[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "mean (Dense)                    (None, 12)           1212        L3[0][0]                         \n",
      "==================================================================================================\n",
      "Total params: 155,712\n",
      "Trainable params: 155,712\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLFW error (code %d): %s 65544 b'Vulkan: Failed to query instance extension count: Initialization of an object could not be completed for implementation-specific reasons'\n",
      "Creating window glfw\n",
      "Episode: 1, Reward: -72.63015281082161\n",
      "upgrade complete 1 times\n",
      "Episode: 2, Reward: -86.50753683159019\n",
      "upgrade complete 2 times\n",
      "Episode: 3, Reward: -57.027668273034735\n",
      "upgrade complete 3 times\n",
      "Episode: 4, Reward: -75.27594569104365\n",
      "upgrade complete 4 times\n",
      "Episode: 5, Reward: -26.499901015953867\n",
      "upgrade complete 5 times\n",
      "Episode: 6, Reward: -42.24325564776184\n",
      "upgrade complete 6 times\n",
      "Episode: 7, Reward: -67.65985392472093\n",
      "upgrade complete 7 times\n",
      "Episode: 8, Reward: -38.56621028869768\n",
      "upgrade complete 8 times\n",
      "Episode: 9, Reward: -16.223039434570616\n",
      "upgrade complete 9 times\n",
      "Episode: 10, Reward: -33.71148739700857\n",
      "upgrade complete 10 times\n",
      "Episode: 11, Reward: -75.09494082301411\n",
      "upgrade complete 11 times\n",
      "Episode: 12, Reward: -53.252569499856754\n",
      "upgrade complete 12 times\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f56c425c9805>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_steps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mSTART_STEPS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\anaconda3\\envs\\mujoco\\lib\\site-packages\\gym\\core.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'human'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\anaconda3\\envs\\mujoco\\lib\\site-packages\\gym\\envs\\mujoco\\mujoco_env.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self, mode, width, height, camera_id, camera_name)\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'human'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_viewer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\anaconda3\\envs\\mujoco\\lib\\site-packages\\mujoco_py-2.0.2.13-py3.6.egg\\mujoco_py\\mjviewer.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    204\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loop_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loop_count\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 206\u001b[1;33m                 \u001b[0mrender_inner_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_loop_count\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;31m# Markers and overlay are regenerated in every pass.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\anaconda3\\envs\\mujoco\\lib\\site-packages\\mujoco_py-2.0.2.13-py3.6.egg\\mujoco_py\\mjviewer.py\u001b[0m in \u001b[0;36mrender_inner_loop\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    180\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_overlay\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_full_overlay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_record_video\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m                 \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_pixels_as_in_window\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\anaconda3\\envs\\mujoco\\lib\\site-packages\\mujoco_py-2.0.2.13-py3.6.egg\\mujoco_py\\mjviewer.py\u001b[0m in \u001b[0;36mrender\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gui_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mglfw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoll_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\anaconda3\\envs\\mujoco\\lib\\site-packages\\mujoco_py-2.0.2.13-py3.6.egg\\mujoco_py\\mjrendercontext.pyx\u001b[0m in \u001b[0;36mmujoco_py.cymj.MjRenderContextWindow.render\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\anaconda3\\envs\\mujoco\\lib\\site-packages\\glfw\\__init__.py\u001b[0m in \u001b[0;36mmake_context_current\u001b[1;34m(window)\u001b[0m\n\u001b[0;32m   2263\u001b[0m         \u001b[0mvoid\u001b[0m \u001b[0mglfwMakeContextCurrent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGLFWwindow\u001b[0m\u001b[1;33m*\u001b[0m \u001b[0mwindow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2264\u001b[0m     \"\"\"\n\u001b[1;32m-> 2265\u001b[1;33m     \u001b[0m_glfw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglfwMakeContextCurrent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2266\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2267\u001b[0m \u001b[0m_glfw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglfwGetCurrentContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPOINTER\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_GLFWwindow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\owner\\anaconda3\\envs\\mujoco\\lib\\site-packages\\glfw\\__init__.py\u001b[0m in \u001b[0;36merrcheck\u001b[1;34m(result, *args)\u001b[0m\n\u001b[0;32m    625\u001b[0m     \u001b[0musing\u001b[0m \u001b[0mthe\u001b[0m \u001b[0m_callback_exception_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m     \"\"\"\n\u001b[1;32m--> 627\u001b[1;33m     \u001b[1;32mdef\u001b[0m \u001b[0merrcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    628\u001b[0m         \u001b[1;32mglobal\u001b[0m \u001b[0m_exc_info_from_callback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_exc_info_from_callback\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    reward_buff_orig = []\n",
    "    reward_buff_my = []\n",
    "    for k in range(2):\n",
    "        for j in range(5):\n",
    "            env_name = \"HalfCheetah-v2\" #\"InvertedPendulum-v2\" \"HalfCheetah-v2\"\n",
    "\n",
    "            MAX_EPISODE_LENGTH = 1000\n",
    "            MAX_SETPS_INTERACTION = 1e6\n",
    "            START_STEPS = 10000\n",
    "\n",
    "\n",
    "            env = gym.make(env_name)\n",
    "            state_dim = env.observation_space.shape[0]\n",
    "            action_dim = env.action_space.shape[0]\n",
    "            action_lim = env.action_space.high[0]\n",
    "\n",
    "            agent = ddpg.DDPG(state_dim, action_dim)\n",
    "\n",
    "            state, reward, done, ep_rew, ep_len, ep_cnt = env.reset(), 0, False, [0.0], 0, 0\n",
    "\n",
    "\n",
    "            for t in range(MAX_SETPS_INTERACTION):\n",
    "\n",
    "                env.render()\n",
    "\n",
    "                if t > START_STEPS:\n",
    "                    action = agent.actor.get_action(state.reshape([1, state_dim]))\n",
    "                    noise = 0.2 * np.random.randn(action_dim)\n",
    "                    action = action_lim * action[0] + noise\n",
    "                else:\n",
    "                    action = env.action_space.sample()\n",
    "                # print(state)\n",
    "\n",
    "                next_state, reward, done, _ = env.step(action)\n",
    "                ep_rew[-1] += reward\n",
    "                ep_len += 1\n",
    "\n",
    "                done = False\n",
    "\n",
    "                if ep_len == MAX_EPISODE_LENGTH:\n",
    "                    done = True\n",
    "\n",
    "                agent.buffer.store(state, action, reward, next_state, done)\n",
    "\n",
    "                state = next_state\n",
    "\n",
    "                if done:\n",
    "                    ep_cnt += 1\n",
    "                    print(f\"Episode: {ep_cnt}, Reward: {ep_rew[-1]}\")\n",
    "\n",
    "                    ep_rew.append(0.0)\n",
    "\n",
    "                    if t > 5000:\n",
    "                        if (k == 1) & (t < 50000):\n",
    "                            for i in range(80):\n",
    "                                agent.replay_train()\n",
    "                        for i in range(200):\n",
    "                            agent.train(False)\n",
    "\n",
    "                            if (i % 5) == 4 :\n",
    "                                agent.targ_update()\n",
    "                    if k == 1:\n",
    "                        if (t >= 8000) & (t < 200000):\n",
    "                            for i in range(50):\n",
    "                                agent.train(True)\n",
    "\n",
    "                    print(\"upgrade complete {} times\".format(ep_cnt))\n",
    "\n",
    "                    state, reward, done, ep_len = env.reset(), 0, False, 0\n",
    "            env.close()\n",
    "            # agent.actor.policy.save('./hg/RL/policy_v1.h5')\n",
    "            # agent.critic.Q.save('./hg/RL/critic_v1.h5')\n",
    "\n",
    "            if k == 0:\n",
    "                reward_buff_orig.append(ep_rew[:-1])\n",
    "            else:\n",
    "                reward_buff_my.append(ep_rew[:-1])\n",
    "\n",
    "\n",
    "    x = np.arange(1, len(ep_rew[:-1])+1)\n",
    "\n",
    "    orig_m = np.mean(reward_buff_orig, 0)\n",
    "    orig_v = np.var(reward_buff_orig,0)/10\n",
    "\n",
    "\n",
    "    my_m = np.mean(reward_buff_my, 0)\n",
    "    my_v = np.var(reward_buff_my,0)/10\n",
    "    #Plot learning curve\n",
    "    plt.style.use('seaborn')\n",
    "    plt.plot(x,orig_m,label = 'Orig')\n",
    "    plt.plot(x, my_m, label='My')\n",
    "    plt.fill_between(x, orig_m - orig_v, orig_m + orig_v, alpha=0.1)\n",
    "    plt.fill_between(x, my_m - my_v, my_m + my_v, alpha=0.1)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Total Reward')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ccc7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "끄면 안된다!! mean variance 다시 그려봐야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c32f9e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
       "array([ 0.81647354,  0.72891515, -0.6065771 ,  0.48404336,  0.69160944,\n",
       "       -0.42976898], dtype=float32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal([6],mean=np.array([ 0.82147634,  0.73499256, -0.6131262,   0.5014195,   0.69987595, -0.43409586]),stddev =np.array([0.01,0.01,0.01,0.01,0.01,0.01]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a3bb876b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "0\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in A[:,1].argsort():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a8d2351",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (5,) (5,2) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-eddf26d5520f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m&\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (5,) (5,2) "
     ]
    }
   ],
   "source": [
    "B = np.where(A[:,1]>A[:,0]& A.argsort())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d327a619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e905b383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.10643632, -0.07471703, -0.02226638,  0.27659905,  0.29793525,\n",
       "        0.23814709,  0.03977355,  0.1456464 , -0.48197963,  0.66352945,\n",
       "        2.41117456, -0.38686714, -6.01247742, -1.52655131, -6.75825172,\n",
       "       -0.10921864,  4.05038801])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c048d7d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.564493851048986"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(np.square(-0.07471703-(-3.141592/9))+np.square(-0.02226638-(1.05/2))+np.square(0.27659905-(0.785/5))\\\n",
    "                                             +np.square( 0.29793525-(-0.4))+np.square(0.23814709-(0.7/2))+np.square(0.03977355-(0))\\\n",
    "                                             +np.square(0.1456464-(0))+np.square(-0.48197963-(5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a45b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da322a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = env.action_space.sample()\n",
    "action[0] = 0\n",
    "action[1] = 0\n",
    "action[2] = 0\n",
    "action[3] = 0\n",
    "action[4] = 0\n",
    "action[5] = 0\n",
    "print(type(action))\n",
    "print(action)\n",
    "next_state, reward, done, _ = env.step(action)\n",
    "print(reward)\n",
    "print(next_state)\n",
    "env.render()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
